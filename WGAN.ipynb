{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60036ab4-51b9-4f1e-a4ec-9dd8d52a1a09",
   "metadata": {},
   "source": [
    "IMPORT ALL THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59ba89d-5385-4b97-acd6-9c5ae73852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from scipy import linalg\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import HTML\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.animation as animation\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ca3bd-3682-4226-bd72-640bbd26c99a",
   "metadata": {},
   "source": [
    "DEFINE THE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfd2711-b5f6-4b77-8ad1-65c8f7da3ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3  \n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 30\n",
    "FEATURES_DISC = 64 \n",
    "FEATURES_GEN = 64 \n",
    "criticItr = 5\n",
    "lambda_GP = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc18e0f-d34f-47f0-999a-ac8d946eb6db",
   "metadata": {},
   "source": [
    "LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e318e7-3a08-4ed7-ab3f-fc73b6eade13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = datasets.CIFAR10(root=\"./CIFAR_dataset/CIFAR10data\", download=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddcb11-303a-47aa-8018-b3e240276a2a",
   "metadata": {},
   "source": [
    "DEFINE THE DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c62156-5088-49e5-ac57-40b96c2261a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self.Dnet(features_d, features_d * 2, 4, 2, 1),     \n",
    "            self.Dnet(features_d * 2, features_d * 4, 4, 2, 1), \n",
    "            self.Dnet(features_d * 4, features_d * 8, 4, 2, 1),  \n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "        \n",
    "    def Dnet(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine =True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e4b2f-5202-4b09-b12e-bb6dac14e340",
   "metadata": {},
   "source": [
    "DEFINE THE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897b593c-86bd-49d5-bb9e-d68adc2612e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self.Gnet(channels_noise, features_g*8, 4, 1, 0),        \n",
    "            self.Gnet(features_g*8, features_g*4, 4, 2, 1),\n",
    "            self.Gnet(features_g*4, features_g*2, 4, 2, 1), \n",
    "            self.Gnet(features_g*2, features_g, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh() \n",
    "        \n",
    "        )\n",
    "        \n",
    "    def Gnet(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels,momentum=0.9),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc57d1d2-c458-4b35-bf94-9ee056e9cacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6184423f-e606-42f2-a8fd-fab2b7f106bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GP (critic, real, fake):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bef7df-27a9-4634-89bb-744152cf53f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    if model == 'gen':\n",
    "        torch.save(model, \"Models/CIFAR_wganGP_GENERATOR.pth.tar\")\n",
    "    elif model == 'disc':\n",
    "        torch.save(model, \"Models/CIFAR_wganGP_DIS.pth.tar\")\n",
    "        \n",
    "def load_model(gen,disc):\n",
    "    gen = torch.load(\"Models/CIFAR_wganGP_GENERATOR.pth.tar\")\n",
    "    disc = torch.load(\"Models/CIFAR_wganGP_DIS.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b34959-8f38-4805-8b3d-f4902899ac4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "optimGenerator = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "optimDiscriminator = optim.RMSprop(disc.parameters(), lr=LEARNING_RATE)\n",
    "fixed_noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b945a6f3-9378-4c95-97ff-aead2e72ca31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Generator(\n",
       "   (net): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "     )\n",
       "     (3): Sequential(\n",
       "       (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "     )\n",
       "     (4): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "     (5): Tanh()\n",
       "   )\n",
       " ),\n",
       " Discriminator(\n",
       "   (disc): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "     (1): LeakyReLU(negative_slope=0.2)\n",
       "     (2): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "       (2): LeakyReLU(negative_slope=0.2)\n",
       "     )\n",
       "     (3): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "       (2): LeakyReLU(negative_slope=0.2)\n",
       "     )\n",
       "     (4): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "       (2): LeakyReLU(negative_slope=0.2)\n",
       "     )\n",
       "     (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.train() , disc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214e36b0-0c87-4c68-a2d8-fa750170e198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnarkhe/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mnarkhe/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    \n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   \n",
    "        192: 1, \n",
    "        768: 2, \n",
    "        2048: 3 \n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "        \n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "            \n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x,\n",
    "                              size=(299, 299),\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1 \n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "model = InceptionV3([block_idx])\n",
    "model=model.cuda()\n",
    "\n",
    "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
    "                    cuda=False):\n",
    "    model.eval()\n",
    "    act=np.empty((len(images), dims))\n",
    "    \n",
    "    if cuda:\n",
    "        batch=images.cuda()\n",
    "    else:\n",
    "        batch=images\n",
    "    pred = model(batch)[0]\n",
    "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n",
    "def calculate_fretchet(images_real,images_fake,model):\n",
    "    mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
    "    mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
    "    \n",
    "    \"\"\"get fretched distance\"\"\"\n",
    "    fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
    "    return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a2660-562b-48be-b895-9011e6947d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== WGAN-GP Training Initialization =====\n",
      "\n",
      "[STATUS] Training Started\n",
      "\n",
      "[EPOCH 1/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 0\n",
      "[EPOCH SUMMARY] Epoch 1:\n",
      "  Average Discriminator Loss: -12569.5932\n",
      "  Average Generator Loss: 32620.9774\n",
      "  FID Score: 228.6168\n",
      "[SAVE] Fake images saved for epoch 1\n",
      "[SAVE] Real images saved for epoch 1\n",
      "\n",
      "[EPOCH 2/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 500\n",
      "[EPOCH SUMMARY] Epoch 2:\n",
      "  Average Discriminator Loss: -5079.7074\n",
      "  Average Generator Loss: 35449.9105\n",
      "  FID Score: 218.8400\n",
      "[SAVE] Fake images saved for epoch 2\n",
      "[SAVE] Real images saved for epoch 2\n",
      "\n",
      "[EPOCH 3/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 1000\n",
      "[EPOCH SUMMARY] Epoch 3:\n",
      "  Average Discriminator Loss: -3893.4211\n",
      "  Average Generator Loss: 35251.5948\n",
      "  FID Score: 219.9726\n",
      "[SAVE] Fake images saved for epoch 3\n",
      "[SAVE] Real images saved for epoch 3\n",
      "\n",
      "[EPOCH 4/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 1500\n",
      "[EPOCH SUMMARY] Epoch 4:\n",
      "  Average Discriminator Loss: -3454.5563\n",
      "  Average Generator Loss: 38272.2794\n",
      "  FID Score: 223.0532\n",
      "[SAVE] Fake images saved for epoch 4\n",
      "[SAVE] Real images saved for epoch 4\n",
      "\n",
      "[EPOCH 5/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 5:\n",
      "  Average Discriminator Loss: -3229.9111\n",
      "  Average Generator Loss: 40259.3499\n",
      "  FID Score: 226.4084\n",
      "[SAVE] Fake images saved for epoch 5\n",
      "[SAVE] Real images saved for epoch 5\n",
      "\n",
      "[EPOCH 6/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 2000\n",
      "[EPOCH SUMMARY] Epoch 6:\n",
      "  Average Discriminator Loss: -3095.7719\n",
      "  Average Generator Loss: 43355.0866\n",
      "  FID Score: 214.8653\n",
      "[SAVE] Fake images saved for epoch 6\n",
      "[SAVE] Real images saved for epoch 6\n",
      "\n",
      "[EPOCH 7/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 2500\n",
      "[EPOCH SUMMARY] Epoch 7:\n",
      "  Average Discriminator Loss: -2965.3214\n",
      "  Average Generator Loss: 45169.2888\n",
      "  FID Score: 213.9338\n",
      "[SAVE] Fake images saved for epoch 7\n",
      "[SAVE] Real images saved for epoch 7\n",
      "\n",
      "[EPOCH 8/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 3000\n",
      "[EPOCH SUMMARY] Epoch 8:\n",
      "  Average Discriminator Loss: -2832.8234\n",
      "  Average Generator Loss: 47552.6538\n",
      "  FID Score: 223.1514\n",
      "[SAVE] Fake images saved for epoch 8\n",
      "[SAVE] Real images saved for epoch 8\n",
      "\n",
      "[EPOCH 9/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 3500\n",
      "[EPOCH SUMMARY] Epoch 9:\n",
      "  Average Discriminator Loss: -2783.5619\n",
      "  Average Generator Loss: 48555.5154\n",
      "  FID Score: 235.0428\n",
      "[SAVE] Fake images saved for epoch 9\n",
      "[SAVE] Real images saved for epoch 9\n",
      "\n",
      "[EPOCH 10/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 10:\n",
      "  Average Discriminator Loss: -2716.8174\n",
      "  Average Generator Loss: 50343.7623\n",
      "  FID Score: 218.6439\n",
      "[SAVE] Fake images saved for epoch 10\n",
      "[SAVE] Real images saved for epoch 10\n",
      "\n",
      "[EPOCH 11/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 4000\n",
      "[EPOCH SUMMARY] Epoch 11:\n",
      "  Average Discriminator Loss: -2672.4618\n",
      "  Average Generator Loss: 52716.2125\n",
      "  FID Score: 229.2089\n",
      "[SAVE] Fake images saved for epoch 11\n",
      "[SAVE] Real images saved for epoch 11\n",
      "\n",
      "[EPOCH 12/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 4500\n",
      "[EPOCH SUMMARY] Epoch 12:\n",
      "  Average Discriminator Loss: -2601.5874\n",
      "  Average Generator Loss: 55196.7896\n",
      "  FID Score: 217.0888\n",
      "[SAVE] Fake images saved for epoch 12\n",
      "[SAVE] Real images saved for epoch 12\n",
      "\n",
      "[EPOCH 13/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 5000\n",
      "[EPOCH SUMMARY] Epoch 13:\n",
      "  Average Discriminator Loss: -2579.0983\n",
      "  Average Generator Loss: 56182.5142\n",
      "  FID Score: 222.5505\n",
      "[SAVE] Fake images saved for epoch 13\n",
      "[SAVE] Real images saved for epoch 13\n",
      "\n",
      "[EPOCH 14/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 14:\n",
      "  Average Discriminator Loss: -2553.8448\n",
      "  Average Generator Loss: 58822.6660\n",
      "  FID Score: 228.1221\n",
      "[SAVE] Fake images saved for epoch 14\n",
      "[SAVE] Real images saved for epoch 14\n",
      "\n",
      "[EPOCH 15/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 5500\n",
      "[EPOCH SUMMARY] Epoch 15:\n",
      "  Average Discriminator Loss: -2482.7417\n",
      "  Average Generator Loss: 61229.0257\n",
      "  FID Score: 222.8706\n",
      "[SAVE] Fake images saved for epoch 15\n",
      "[SAVE] Real images saved for epoch 15\n",
      "\n",
      "[EPOCH 16/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 6000\n",
      "[EPOCH SUMMARY] Epoch 16:\n",
      "  Average Discriminator Loss: -2483.2916\n",
      "  Average Generator Loss: 64124.5488\n",
      "  FID Score: 227.1843\n",
      "[SAVE] Fake images saved for epoch 16\n",
      "[SAVE] Real images saved for epoch 16\n",
      "\n",
      "[EPOCH 17/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 6500\n",
      "[EPOCH SUMMARY] Epoch 17:\n",
      "  Average Discriminator Loss: -2454.9615\n",
      "  Average Generator Loss: 65745.9715\n",
      "  FID Score: 230.8026\n",
      "[SAVE] Fake images saved for epoch 17\n",
      "[SAVE] Real images saved for epoch 17\n",
      "\n",
      "[EPOCH 18/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 7000\n",
      "[EPOCH SUMMARY] Epoch 18:\n",
      "  Average Discriminator Loss: -2435.4540\n",
      "  Average Generator Loss: 67312.7962\n",
      "  FID Score: 225.7870\n",
      "[SAVE] Fake images saved for epoch 18\n",
      "[SAVE] Real images saved for epoch 18\n",
      "\n",
      "[EPOCH 19/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 19:\n",
      "  Average Discriminator Loss: -2419.5489\n",
      "  Average Generator Loss: 69873.4949\n",
      "  FID Score: 234.0645\n",
      "[SAVE] Fake images saved for epoch 19\n",
      "[SAVE] Real images saved for epoch 19\n",
      "\n",
      "[EPOCH 20/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 7500\n",
      "[EPOCH SUMMARY] Epoch 20:\n",
      "  Average Discriminator Loss: -2423.3302\n",
      "  Average Generator Loss: 70813.5969\n",
      "  FID Score: 225.8649\n",
      "[SAVE] Fake images saved for epoch 20\n",
      "[SAVE] Real images saved for epoch 20\n",
      "\n",
      "[EPOCH 21/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 8000\n",
      "[EPOCH SUMMARY] Epoch 21:\n",
      "  Average Discriminator Loss: -2404.6275\n",
      "  Average Generator Loss: 72336.5783\n",
      "  FID Score: 221.3321\n",
      "[SAVE] Fake images saved for epoch 21\n",
      "[SAVE] Real images saved for epoch 21\n",
      "\n",
      "[EPOCH 22/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 8500\n",
      "[EPOCH SUMMARY] Epoch 22:\n",
      "  Average Discriminator Loss: -2415.4451\n",
      "  Average Generator Loss: 75695.4951\n",
      "  FID Score: 226.2531\n",
      "[SAVE] Fake images saved for epoch 22\n",
      "[SAVE] Real images saved for epoch 22\n",
      "\n",
      "[EPOCH 23/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 23:\n",
      "  Average Discriminator Loss: -2391.3874\n",
      "  Average Generator Loss: 78813.6693\n",
      "  FID Score: 208.4160\n",
      "[SAVE] Fake images saved for epoch 23\n",
      "[SAVE] Real images saved for epoch 23\n",
      "\n",
      "[EPOCH 24/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 9000\n",
      "[EPOCH SUMMARY] Epoch 24:\n",
      "  Average Discriminator Loss: -2364.9927\n",
      "  Average Generator Loss: 81414.8549\n",
      "  FID Score: 229.4379\n",
      "[SAVE] Fake images saved for epoch 24\n",
      "[SAVE] Real images saved for epoch 24\n",
      "\n",
      "[EPOCH 25/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 9500\n",
      "[EPOCH SUMMARY] Epoch 25:\n",
      "  Average Discriminator Loss: -2385.0519\n",
      "  Average Generator Loss: 83659.0125\n",
      "  FID Score: 221.9817\n",
      "[SAVE] Fake images saved for epoch 25\n",
      "[SAVE] Real images saved for epoch 25\n",
      "\n",
      "[EPOCH 26/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 10000\n",
      "[EPOCH SUMMARY] Epoch 26:\n",
      "  Average Discriminator Loss: -2383.8067\n",
      "  Average Generator Loss: 85760.5706\n",
      "  FID Score: 225.5396\n",
      "[SAVE] Fake images saved for epoch 26\n",
      "[SAVE] Real images saved for epoch 26\n",
      "\n",
      "[EPOCH 27/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 10500\n",
      "[EPOCH SUMMARY] Epoch 27:\n",
      "  Average Discriminator Loss: -2377.4473\n",
      "  Average Generator Loss: 88634.4787\n",
      "  FID Score: 224.9115\n",
      "[SAVE] Fake images saved for epoch 27\n",
      "[SAVE] Real images saved for epoch 27\n",
      "\n",
      "[EPOCH 28/30] Beginning training\n",
      "[EPOCH SUMMARY] Epoch 28:\n",
      "  Average Discriminator Loss: -2368.2665\n",
      "  Average Generator Loss: 91002.6756\n",
      "  FID Score: 227.3277\n",
      "[SAVE] Fake images saved for epoch 28\n",
      "[SAVE] Real images saved for epoch 28\n",
      "\n",
      "[EPOCH 29/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 11000\n",
      "[EPOCH SUMMARY] Epoch 29:\n",
      "  Average Discriminator Loss: -2361.0859\n",
      "  Average Generator Loss: 92571.4900\n",
      "  FID Score: 225.9541\n",
      "[SAVE] Fake images saved for epoch 29\n",
      "[SAVE] Real images saved for epoch 29\n",
      "\n",
      "[EPOCH 30/30] Beginning training\n",
      "[IMAGE SAVE] Saved generated images at iteration 11500\n"
     ]
    }
   ],
   "source": [
    "GenLoss = []\n",
    "DiscLoss = []\n",
    "DiscLossP = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "FID_list = []\n",
    "\n",
    "print(\"===== WGAN-GP Training Initialization =====\")\n",
    "\n",
    "print(\"\\n[STATUS] Training Started\")\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch = epoch+1\n",
    "    epoch_gen_loss = 0.0\n",
    "    epoch_disc_loss = 0.0\n",
    "    \n",
    "    print(f\"\\n[EPOCH {epoch}/{NUM_EPOCHS}] Beginning training\")\n",
    "    \n",
    "    for batch_idx, data in enumerate(dataloader,0):\n",
    "        real = data[0].to(device)\n",
    "        batch = real.shape[0]\n",
    "        \n",
    "        for i in range(criticItr):\n",
    "            noise = torch.randn(batch, NOISE_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = disc(real).reshape(-1)\n",
    "            critic_fake = disc(fake).reshape(-1)\n",
    "            gp = GP(disc, real,fake)\n",
    "            loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake))+ (lambda_GP*gp))\n",
    "            disc.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            optimDiscriminator.step()\n",
    "            \n",
    "            epoch_disc_loss += loss_critic.item()\n",
    "        \n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(output) \n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        optimGenerator.step()\n",
    "        \n",
    "        epoch_gen_loss += loss_gen.item()\n",
    "        \n",
    "        GenLoss.append(loss_gen.detach().cpu())\n",
    "        DiscLoss.append(loss_critic.detach().cpu())\n",
    "        \n",
    "        if (iters % 500 == 0) or ((epoch == NUM_EPOCHS) and (batch_idx == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).detach().cpu()\n",
    "            img_list.append(utils.make_grid(fake, padding=2, normalize=True))\n",
    "            print(f\"[IMAGE SAVE] Saved generated images at iteration {iters}\")\n",
    "            \n",
    "        iters += 1\n",
    "    \n",
    "    fretchet_dist = calculate_fretchet(real,fake,model)\n",
    "    FID_list.append(fretchet_dist)\n",
    "    \n",
    "    print(f\"[EPOCH SUMMARY] Epoch {epoch}:\")\n",
    "    print(f\"  Average Discriminator Loss: {epoch_disc_loss/criticItr:.4f}\")\n",
    "    print(f\"  Average Generator Loss: {epoch_gen_loss:.4f}\")\n",
    "    print(f\"  FID Score: {fretchet_dist:.4f}\")\n",
    "    \n",
    "    labels = torch.arange(0,10,dtype=torch.long,device=device)\n",
    "    noise = torch.randn(10,100,device=device)  \n",
    "    images = gen(fixed_noise)\n",
    "    \n",
    "    os.makedirs('Results/WGANGP_FAKE', exist_ok=True)\n",
    "    os.makedirs('Results/WGANGP_REAL', exist_ok=True)\n",
    "    \n",
    "    utils.save_image(images.detach(), f'Results/WGANGP_FAKE/WGANGP_epoch_{epoch:03d}.png', normalize=True)\n",
    "    print(f\"[SAVE] Fake images saved for epoch {epoch}\")\n",
    "    \n",
    "    real = data[0].to(device)\n",
    "    utils.save_image(real.detach(), f'Results/WGANGP_REAL/WGANGP_epoch_{epoch:03d}.png', normalize=True)\n",
    "    print(f\"[SAVE] Real images saved for epoch {epoch}\")\n",
    "        \n",
    "time_end = time.time()\n",
    "total_training_time = time_end - time_start\n",
    "\n",
    "print(\"\\n===== Training Completed =====\")\n",
    "print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
    "print(f\"Average Time per Epoch: {total_training_time/NUM_EPOCHS:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd8232-91c1-4a5e-a02f-4dd04e5ef1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Results/Loss_Data/WGANGP_GLoss', GenLoss) \n",
    "np.save('Results/Loss_Data/WGANGP_DLoss', DiscLoss) \n",
    "GenLoss = np.load('Results/Loss_Data/WGANGP_GLoss.npy')\n",
    "DiscLoss = np.load('Results/Loss_Data/WGANGP_DLoss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820640f3-f604-47f7-a988-4ff888ac6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(GenLoss,label=\"Generator\", color='green')\n",
    "plt.plot(DiscLoss,label=\"Discriminator\", color='red')\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('Results/Loss.pdf',\n",
    "            format='pdf',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9246f73-0ca0-48c4-a5dc-a179a843a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(real_batch[0].to(device)[:64], padding=1, normalize=True).cpu(),(1,2,0)))\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.savefig('Results/WGANGP_BEST_FAKE_32.pdf',\n",
    "            format='pdf',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf37373-039b-4542-9dbc-c50327dffa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"FID Scores for WGANGP\")\n",
    "plt.plot(FID_list,label=\"WGANGP\", color='green')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"FID\")\n",
    "plt.legend()\n",
    "plt.savefig('Results/FID.pdf',\n",
    "            format='pdf',\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60eb22-211c-41db-94f5-f6e5bd6876b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(GenLoss),np.mean(DiscLoss),np.min(GenLoss),np.min(DiscLoss),GenLoss[-1],DiscLoss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837717ea-2ef8-4698-811c-2c4643c92a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.min(FID_list), np.max(FID_list), np.mean(FID_list), FID_list[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
